# 回帰分析  

## 単回帰分析

誤差$E$が最小になるように，データ点を$y=\beta_0 + \beta_{1}x$の直線で回帰する．

$$E = \sum_i (y_i - (\beta_0 + \beta_1 x_i))^2$$

## 重回帰分析  
複数の説明変数を用いて，$y=\beta_0 +\sum_i{\beta_i x_i}$で回帰する．  

- 偏回帰係数  
各特徴の重み$\beta_i$のこと．

- 標準偏回帰係数  
標準された$X,y$から算出される偏回帰係数．  

## 偏回帰係数の有意性の検定
各偏回帰係数$\hat{\beta}_i$が0であるかを検定する．  
$H_0$:偏回帰係数=0  
統計量tは自由度$(n-k-1)$のt分布に従うので，次のようになる($k$は特徴の数，$se$は標準誤差)．
$$t_i=\frac{\hat{\beta}_i -0}{se(\hat{\beta}_i)}$$

## 偏回帰係数の信頼区間  
$$\hat{\beta}_i - t_{\frac{\alpha}{2}}(n-k-1) se(\hat{\beta}_i) \quad \leq \beta_i \leq \quad \hat{\beta}_i + t_{\frac{\alpha}{2}}(n-k-1) se(\hat{\beta}_i)$$

## 決定係数  
説明変数が目的変数をどれくらい説明しているか，あるいは残差変動が全変動に対してどれだけ少ないかを示す．
$$R^2 = 1 - \frac{\sum_i (y_i-\hat{y}_i)^2}{\sum_i (y_i-\bar{y})^2}$$

## 自由度調整済み決定係数  
決定係数は説明変数が多いほど1に近づくため，説明変数の数に対して正規化したもの．
$$R^2_f = 1 - \frac{\sum_i (y_i-\hat{y}_i)^2 / (n-k-1)}{\sum_i (y_i-\bar{y})^2 / (n-1)}$$