{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factorization Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 3, 1, 4, 5, 1, 5]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alice</th>\n",
       "      <th>Bob</th>\n",
       "      <th>Chris</th>\n",
       "      <th>TITANIC</th>\n",
       "      <th>NOTTING HILL</th>\n",
       "      <th>STARWARS</th>\n",
       "      <th>STARTREK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alice  Bob  Chris  TITANIC  NOTTING HILL  STARWARS  STARTREK\n",
       "0      1    0      0        1             0         0         0\n",
       "1      1    0      0        0             1         0         0\n",
       "2      1    0      0        0             0         1         0\n",
       "3      0    1      0        0             0         1         0\n",
       "4      0    1      0        0             0         0         1\n",
       "5      0    0      1        1             0         0         0\n",
       "6      0    0      1        0             0         1         0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_movies = ['Alice', 'Bob', 'Chris',\n",
    "                            'TITANIC', 'NOTTING HILL', 'STARWARS', 'STARTREK']\n",
    "data = pd.DataFrame([\n",
    "    [1,0,0,1,0,0,0],\n",
    "    [1,0,0,0,1,0,0],\n",
    "    [1,0,0,0,0,1,0],\n",
    "    [0,1,0,0,0,1,0],\n",
    "    [0,1,0,0,0,0,1],\n",
    "    [0,0,1,1,0,0,0],\n",
    "    [0,0,1,0,0,1,0]], \n",
    "    columns=users_movies)\n",
    "\n",
    "target = [5,3,1,4,5,1,5]\n",
    "\n",
    "print(target)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 原理 \n",
    "\n",
    "次の式をNNで再現する．  \n",
    "$$ \\hat{y}({\\bf x}) = w_0 + \\sum^N_{i=1} w_i x_i + \\sum^N_{i=1} \\sum^N_{j=i+1} (v_i \\cdot v_j) x_i x_j $$\n",
    "第1項，第2項は線形モデル，つまりNNの全結合層で表せる．  \n",
    "第3項は次のようになる．  \n",
    "$$ \\sum^N_{i=1} \\sum^N_{j=i+1} (v_i \\cdot v_j) x_i x_j = \\frac{1}{2} \\sum_{f=1}^{k} \\Big( \\big(\\sum_{i=1}^{n} v_f^{(i)} x_i \\big)^2 - \\sum_{i=1}^{n}v_f^{(i) 2} x_i^2 \\Big) \\\\ = \n",
    "\\frac{1}{2} \\sum_{f=1}^{} \\Big( S_{1,f}^2 - S_{2,f} \\Big)\\\\ =\n",
    "\\frac{1}{2} \\Big( S_{1}^2 - S_{2} \\Big) $$\n",
    "\n",
    "データ数$N$，特徴次元数$d$，分解次元数(ハイパーパラメータ)$k$とおくと，\n",
    "x.shape = $(N, d) $  \n",
    "v.shape = $(d, k) $\n",
    "\n",
    "$XV$を計算すると，次のような要素が現れるので，要素ごとに2乗して合計をとれば$S_1^2$が求まる．  \n",
    "同様に，$X$と$V$を要素ごとに2乗して，それらを掛けて合計を取れば$S_2$が求まる．($vx$の積で表現した第3項と対応する要素が$XV$行列にある)\n",
    "\n",
    "$$\n",
    "XV = \\begin{bmatrix}\n",
    "\\sum_{i=1}^{n} v_f^{(1)} x_i^{(1)}  & \\dots &  \\sum_{i=1}^{n} v_f^{(k)} x_i^{(1)}\\\\\n",
    " \\vdots \\ & \\ddots \\ & \\vdots \\\\ \n",
    "\\sum_{i=1}^{n} v_f^{(1)} x_i^{(M)} & \\dots & \\sum_{i=1}^{n} v_f^{(k)} x_i^{(M)} \\\\\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "S_{11}^{(1)}  & \\dots &  S_{1k}^{(1)}\\\\\n",
    " \\vdots \\ & \\ddots \\ & \\vdots \\\\ \n",
    "S_{11}^{(M)}  & \\dots & S_{1k}^{(M)} \\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "したがって，最終的に実装する式は次のようになる．  \n",
    "$$\\hat{y}({\\bf X}) = w_0 + \\sum^N_{i=1} w_i x_i + \\frac{1}{2} \\sum_{row}( f(XV) - f(X) \\times f(V))$$\n",
    "$$f : {\\rm element \\, wise \\, square}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FactorizationMachine(nn.Module):\n",
    "    def __init__(self, dim=None, k=None):\n",
    "        super().__init__()\n",
    "        self.V = nn.Parameter(torch.randn(dim,k), requires_grad=True)\n",
    "        self.fc = nn.Linear(dim, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        linear_term = self.fc(x)\n",
    "        s1_squared = torch.matmul(x, self.V)\\\n",
    "                                          .pow(2)\\\n",
    "                                          .sum(1, keepdim=True)\n",
    "        s2 = torch.matmul(x.pow(2), self.V.pow(2))\\\n",
    "                          .sum(1, keepdim=True)\n",
    "        out = .5 * (s1_squared - s2)\n",
    "        out = out + linear_term\n",
    "        return out\n",
    "    \n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main training function\n",
    "def train_mlp(X, X_test, y, folds, model_class=None, model_params=None, batch_size=128, epochs=1,\n",
    "              criterion=None, optimizer_class=None, opt_params=None,\n",
    "#               clr=cyclical_lr(10000),\n",
    "              device=None):\n",
    "    \n",
    "    seed_everything()\n",
    "    models = []\n",
    "    scores = []\n",
    "    train_preds = np.zeros(y.shape)\n",
    "    test_preds = np.zeros((X_test.shape[0], 1))\n",
    "    \n",
    "    X_tensor, X_test, y_tensor = torch.from_numpy(X).to(device), torch.from_numpy(X_test).to(device), torch.from_numpy(y).to(device)\n",
    "    for n_fold, (train_ind, valid_ind) in enumerate(folds.split(X, y)):\n",
    "        \n",
    "        print(f'fold {n_fold+1}')\n",
    "        \n",
    "        train_set = TensorDataset(X_tensor[train_ind], y_tensor[train_ind])\n",
    "        valid_set = TensorDataset(X_tensor[valid_ind], y_tensor[valid_ind])\n",
    "        \n",
    "        loaders = {'train': DataLoader(train_set, batch_size=batch_size, shuffle=True),\n",
    "                   'valid': DataLoader(valid_set, batch_size=batch_size, shuffle=False)}\n",
    "        \n",
    "        model = model_class(**model_params)\n",
    "        model.to(device)\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "        optimizer = optimizer_class(model.parameters(), **opt_params)\n",
    "        \n",
    "        # training cycle\n",
    "        best_score = 0.\n",
    "        for epoch in range(epochs):\n",
    "            losses = {'train': 0., 'valid': 0}\n",
    "            \n",
    "            for phase in ['train', 'valid']:\n",
    "               \n",
    "                if phase == 'train':\n",
    "                    model.train()\n",
    "                else:\n",
    "                    model.eval()\n",
    "                \n",
    "                for batch_x, batch_y in loaders[phase]:\n",
    "                    optimizer.zero_grad()\n",
    "                    out = model(batch_x)\n",
    "                    loss = criterion(out, batch_y)\n",
    "                    losses[phase] += loss.item()*batch_x.size(0)\n",
    "                    \n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                losses[phase] /= len(loaders[phase].dataset)\n",
    "            \n",
    "            # after each epoch check if we improved roc auc and if yes - save model\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                valid_preds = sigmoid(model(X_tensor[valid_ind]).cpu().numpy())\n",
    "                try:\n",
    "                    epoch_score = roc_auc_score(y[valid_ind], valid_preds)\n",
    "                except:\n",
    "                    epoch_score = 0.5\n",
    "                if epoch_score > best_score:\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                    best_score = epoch_score\n",
    "            \n",
    "            if ((epoch+1) % 30) == 0:\n",
    "                print(f'ep {epoch+1} loss: {losses[\"train\"]:.3f} loss_val {losses[\"valid\"]:.3f} auc_val {epoch_score:.3f}')\n",
    "        \n",
    "        # prediction on valid set\n",
    "        with torch.no_grad():\n",
    "            model.load_state_dict(best_model_wts)\n",
    "            model.eval()\n",
    "            \n",
    "            train_preds[valid_ind] = sigmoid(model(X_tensor[valid_ind]).cpu().numpy())\n",
    "            try:\n",
    "                fold_score = roc_auc_score(y[valid_ind], train_preds[valid_ind])\n",
    "            except:\n",
    "                fold_score = 0.5\n",
    "            scores.append(fold_score)\n",
    "            print(f'Best ROC AUC score {fold_score}')\n",
    "            models.append(model)\n",
    "\n",
    "            test_preds += sigmoid(model(X_test).cpu().numpy())\n",
    "    \n",
    "    print('CV AUC ROC', np.mean(scores), np.std(scores))\n",
    "    \n",
    "    test_preds /= folds.n_splits\n",
    "    \n",
    "    return models, train_preds, test_preds    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alice</th>\n",
       "      <th>Bob</th>\n",
       "      <th>Chris</th>\n",
       "      <th>TITANIC</th>\n",
       "      <th>NOTTING HILL</th>\n",
       "      <th>STARWARS</th>\n",
       "      <th>STARTREK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alice  Bob  Chris  TITANIC  NOTTING HILL  STARWARS  STARTREK\n",
       "0      1    0      0        0             0         0         1\n",
       "1      0    1      0        1             0         0         0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = data\n",
    "test_df = pd.DataFrame([[1,0,0,0,0,0,1], [0,1,0,1,0,0,0]], columns=users_movies)\n",
    "\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.values.astype(np.float32)\n",
    "X_test = test_df.values.astype(np.float32)\n",
    "y = np.array(target).astype(np.float32).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chieda/anaconda3/envs/torchenv/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 30 loss: -142172.350 loss_val -56.231 auc_val 0.500\n",
      "Best ROC AUC score 1.0\n",
      "fold 2\n",
      "ep 30 loss: -50096.438 loss_val -25323.180 auc_val 0.500\n",
      "Best ROC AUC score 1.0\n",
      "fold 3\n",
      "ep 30 loss: -15703.262 loss_val -134.576 auc_val 0.500\n",
      "Best ROC AUC score 0.5\n",
      "fold 4\n",
      "ep 30 loss: -144916.516 loss_val 0.000 auc_val 0.500\n",
      "Best ROC AUC score 0.5\n",
      "fold 5\n",
      "ep 30 loss: -24950.921 loss_val -5.176 auc_val 0.500\n",
      "Best ROC AUC score 0.5\n",
      "CV AUC ROC 0.7 0.2449489742783178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chieda/anaconda3/envs/torchenv/lib/python3.6/site-packages/ipykernel_launcher.py:19: RuntimeWarning: overflow encountered in exp\n",
      "/Users/chieda/anaconda3/envs/torchenv/lib/python3.6/site-packages/ipykernel_launcher.py:19: RuntimeWarning: overflow encountered in exp\n",
      "/Users/chieda/anaconda3/envs/torchenv/lib/python3.6/site-packages/ipykernel_launcher.py:19: RuntimeWarning: overflow encountered in exp\n",
      "/Users/chieda/anaconda3/envs/torchenv/lib/python3.6/site-packages/ipykernel_launcher.py:19: RuntimeWarning: overflow encountered in exp\n",
      "/Users/chieda/anaconda3/envs/torchenv/lib/python3.6/site-packages/ipykernel_launcher.py:19: RuntimeWarning: overflow encountered in exp\n",
      "/Users/chieda/anaconda3/envs/torchenv/lib/python3.6/site-packages/ipykernel_launcher.py:19: RuntimeWarning: overflow encountered in exp\n",
      "/Users/chieda/anaconda3/envs/torchenv/lib/python3.6/site-packages/ipykernel_launcher.py:19: RuntimeWarning: overflow encountered in exp\n",
      "/Users/chieda/anaconda3/envs/torchenv/lib/python3.6/site-packages/ipykernel_launcher.py:19: RuntimeWarning: overflow encountered in exp\n",
      "/Users/chieda/anaconda3/envs/torchenv/lib/python3.6/site-packages/ipykernel_launcher.py:19: RuntimeWarning: overflow encountered in exp\n",
      "/Users/chieda/anaconda3/envs/torchenv/lib/python3.6/site-packages/ipykernel_launcher.py:19: RuntimeWarning: overflow encountered in exp\n",
      "/Users/chieda/anaconda3/envs/torchenv/lib/python3.6/site-packages/ipykernel_launcher.py:19: RuntimeWarning: overflow encountered in exp\n"
     ]
    }
   ],
   "source": [
    "MS, train_preds, test_preds = train_mlp(X_train, X_test, y,\n",
    "                            KFold(n_splits=5, random_state=17), \n",
    "                            model_class=FactorizationMachine, \n",
    "                            model_params={'dim': X_train.shape[1], 'k': 5}, \n",
    "                            batch_size=2,\n",
    "                            epochs=50,\n",
    "                            criterion=nn.BCEWithLogitsLoss(),\n",
    "                            optimizer_class=torch.optim.SGD, \n",
    "                            opt_params={'lr': 0.01, 'momentum': 0.9},\n",
    "                            device=DEVICE\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.72969955],\n",
       "       [0.47967553],\n",
       "       [0.25821853],\n",
       "       [0.97765607],\n",
       "       [0.15790828],\n",
       "       [0.9304136 ],\n",
       "       [0.82147592]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5161366 ],\n",
       "       [0.29246324]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 3, 1, 4, 5, 1, 5]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
